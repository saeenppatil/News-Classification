{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78840afb-06e0-4a2a-b025-984962f96775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saee/miniforge3/envs/tf_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "import transformers\n",
    "transformers.is_tf_available = lambda: False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472033b7-fb25-438c-80cd-ec9d46036fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   data_id                                                 id       date  \\\n",
      "0     1809  abcnews--2019-10-31--Virginia mom charged with... 2019-10-31   \n",
      "1     1980  abcnews--2019-11-07--2 escaped murder suspects... 2019-11-07   \n",
      "2     1995  abcnews--2019-11-07--Family turns in escaped b... 2019-11-07   \n",
      "3     2740  abcnews--2019-12-02--Mother charged with murde... 2019-12-02   \n",
      "4     7038  ageofautism--2019-04-12--Physician Father and ... 2019-04-12   \n",
      "\n",
      "        source                                              title  \\\n",
      "0      abcnews  Virginia mom charged with murder in 2-year-old...   \n",
      "1      abcnews  2 escaped murder suspects arrested at US-Mexic...   \n",
      "2      abcnews  Family turns in escaped boy, 13, suspected in ...   \n",
      "3      abcnews  Mother charged with murder in deaths of 2 youn...   \n",
      "4  ageofautism  Physician, Father and Caretaker of 29 Year Old...   \n",
      "\n",
      "                                             content         author  \\\n",
      "0  The Virginia woman whose 2-year-old son was fo...           None   \n",
      "1  Authorities are trying to determine if anyone ...           None   \n",
      "2  A 13-year-old suspect in a double homicide who...           None   \n",
      "3  The mother of two young children found hanging...           None   \n",
      "4  \"One family member said Derek “can be violent ...  Age of Autism   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://abcnews.go.com/US/wireStory/virginia-m...   \n",
      "1  https://abcnews.go.com/US/wireStory/escaped-mu...   \n",
      "2  https://abcnews.go.com/US/wireStory/family-tur...   \n",
      "3  https://abcnews.go.com/US/wireStory/mother-cha...   \n",
      "4  http://feedproxy.google.com/~r/ageofautism/~3/...   \n",
      "\n",
      "                         published  published_utc  collection_utc  \\\n",
      "0  Thu, 31 Oct 2019 16:49:56 -0400     1572554996      1572559512   \n",
      "1  Thu, 07 Nov 2019 00:13:12 -0500     1573103592      1573131986   \n",
      "2  Thu, 07 Nov 2019 07:39:54 -0500     1573130394      1573131982   \n",
      "3  Mon, 02 Dec 2019 11:30:59 -0500     1575304259      1575308811   \n",
      "4        2019-04-12 09:00:00+00:00     1555074000      1567543083   \n",
      "\n",
      "         category_level_1 category_level_2  \n",
      "0  crime, law and justice            crime  \n",
      "1  crime, law and justice            crime  \n",
      "2  crime, law and justice            crime  \n",
      "3  crime, law and justice            crime  \n",
      "4  crime, law and justice            crime  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_json(\"hf://datasets/textminr/mn-ds/train.jsonl\", lines=True)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b216e277-ee70-47cc-bfaa-c105bfb09e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories: ['crime, law and justice', 'arts, culture, entertainment and media', 'economy, business and finance', 'disaster, accident and emergency incident', 'environment', 'education', 'health', 'human interest', 'lifestyle and leisure', 'politics', 'labour', 'religion and belief', 'science and technology', 'society', 'sport', 'conflict, war and peace', 'weather']\n",
      "Category to Index Mapping: {'crime, law and justice': 0, 'arts, culture, entertainment and media': 1, 'economy, business and finance': 2, 'disaster, accident and emergency incident': 3, 'environment': 4, 'education': 5, 'health': 6, 'human interest': 7, 'lifestyle and leisure': 8, 'politics': 9, 'labour': 10, 'religion and belief': 11, 'science and technology': 12, 'society': 13, 'sport': 14, 'conflict, war and peace': 15, 'weather': 16}\n",
      "              category_level_1  encoded_label\n",
      "0       crime, law and justice              0\n",
      "1       crime, law and justice              0\n",
      "2       crime, law and justice              0\n",
      "3       crime, law and justice              0\n",
      "4       crime, law and justice              0\n",
      "...                        ...            ...\n",
      "10912  conflict, war and peace             15\n",
      "10913  conflict, war and peace             15\n",
      "10914  conflict, war and peace             15\n",
      "10915  conflict, war and peace             15\n",
      "10916  conflict, war and peace             15\n",
      "\n",
      "[10917 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# encode current label for model\n",
    "labels = df['category_level_1'].unique()\n",
    "categories = list(labels) \n",
    "print(\"Categories:\", categories)\n",
    "\n",
    "category_to_index = {category: idx for idx, category in enumerate(categories)}\n",
    "print(\"Category to Index Mapping:\", category_to_index)\n",
    "\n",
    "def encode_label(category):\n",
    "    return category_to_index[category]\n",
    "\n",
    "df['encoded_label'] = df['category_level_1'].apply(encode_label)\n",
    "\n",
    "print(df[['category_level_1', 'encoded_label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7491ccf8-53cc-487d-9559-d06f72f81a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['data_id', 'id', 'date', 'source', 'title', 'content', 'author', 'url',\n",
      "       'published', 'published_utc', 'collection_utc', 'category_level_1',\n",
      "       'category_level_2', 'encoded_label'],\n",
      "      dtype='object')\n",
      "0    The Virginia woman whose 2-year-old son was fo...\n",
      "1    Authorities are trying to determine if anyone ...\n",
      "2    A 13-year-old suspect in a double homicide who...\n",
      "3    The mother of two young children found hanging...\n",
      "4    \"One family member said Derek “can be violent ...\n",
      "Name: content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# preprocess data for model \n",
    "print(df.columns) \n",
    "print(df['content'].head()) \n",
    "\n",
    "df = df.dropna(subset=['content'])\n",
    "df = df[df['content'].str.strip() != ''] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7fce231-b9c7-44ae-a1b5-c2f6131298a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       data_id                                                 id       date  \\\n",
      "0         1809  abcnews--2019-10-31--Virginia mom charged with... 2019-10-31   \n",
      "1         1980  abcnews--2019-11-07--2 escaped murder suspects... 2019-11-07   \n",
      "2         1995  abcnews--2019-11-07--Family turns in escaped b... 2019-11-07   \n",
      "3         2740  abcnews--2019-12-02--Mother charged with murde... 2019-12-02   \n",
      "4         7038  ageofautism--2019-04-12--Physician Father and ... 2019-04-12   \n",
      "...        ...                                                ...        ...   \n",
      "10912   907640  therussophileorg--2019-12-15--Iran to build ov... 2019-12-15   \n",
      "10913   892720  therussophileorg--2019-10-12--Ukraine has no m... 2019-10-12   \n",
      "10914   870499  therussophileorg--2019-07-06--Irans contributi... 2019-07-06   \n",
      "10915   887334  therussophileorg--2019-09-25--Iraqi president ... 2019-09-25   \n",
      "10916   885988  therussophileorg--2019-09-20--Russia expects t... 2019-09-20   \n",
      "\n",
      "                 source                                              title  \\\n",
      "0               abcnews  Virginia mom charged with murder in 2-year-old...   \n",
      "1               abcnews  2 escaped murder suspects arrested at US-Mexic...   \n",
      "2               abcnews  Family turns in escaped boy, 13, suspected in ...   \n",
      "3               abcnews  Mother charged with murder in deaths of 2 youn...   \n",
      "4           ageofautism  Physician, Father and Caretaker of 29 Year Old...   \n",
      "...                 ...                                                ...   \n",
      "10912  therussophileorg  Iran to build over 30,000 housing units in Syr...   \n",
      "10913  therussophileorg  Ukraine has no money for reconstruction of Don...   \n",
      "10914  therussophileorg  Iran’s contribution is needed to rebuild Iraq ...   \n",
      "10915  therussophileorg  Iraqi president demands international help for...   \n",
      "10916  therussophileorg  Russia expects to cooperate with China on Syri...   \n",
      "\n",
      "                                                 content            author  \\\n",
      "0      The Virginia woman whose 2-year-old son was fo...              None   \n",
      "1      Authorities are trying to determine if anyone ...              None   \n",
      "2      A 13-year-old suspect in a double homicide who...              None   \n",
      "3      The mother of two young children found hanging...              None   \n",
      "4      \"One family member said Derek “can be violent ...     Age of Autism   \n",
      "...                                                  ...               ...   \n",
      "10912  This post was originally published on this sit...         News Desk   \n",
      "10913  This post was originally published on this sit...  Michael Sullivan   \n",
      "10914  This  [post](http://www.presstv.ir/Detail/2019...  Michael Sullivan   \n",
      "10915  This  [post](http://www.presstv.ir/Detail/2019...  Michael Sullivan   \n",
      "10916  This  [post](https://tass.com/politics/1079130...  Michael Sullivan   \n",
      "\n",
      "                                                     url  \\\n",
      "0      https://abcnews.go.com/US/wireStory/virginia-m...   \n",
      "1      https://abcnews.go.com/US/wireStory/escaped-mu...   \n",
      "2      https://abcnews.go.com/US/wireStory/family-tur...   \n",
      "3      https://abcnews.go.com/US/wireStory/mother-cha...   \n",
      "4      http://feedproxy.google.com/~r/ageofautism/~3/...   \n",
      "...                                                  ...   \n",
      "10912  https://www.therussophile.org/iran-to-build-ov...   \n",
      "10913  https://www.therussophile.org/ukraine-has-no-m...   \n",
      "10914  https://www.therussophile.org/irans-contributi...   \n",
      "10915  https://www.therussophile.org/iraqi-president-...   \n",
      "10916  https://www.therussophile.org/russia-expects-t...   \n",
      "\n",
      "                             published  published_utc  collection_utc  \\\n",
      "0      Thu, 31 Oct 2019 16:49:56 -0400     1572554996      1572559512   \n",
      "1      Thu, 07 Nov 2019 00:13:12 -0500     1573103592      1573131986   \n",
      "2      Thu, 07 Nov 2019 07:39:54 -0500     1573130394      1573131982   \n",
      "3      Mon, 02 Dec 2019 11:30:59 -0500     1575304259      1575308811   \n",
      "4            2019-04-12 09:00:00+00:00     1555074000      1567543083   \n",
      "...                                ...            ...             ...   \n",
      "10912  Sun, 15 Dec 2019 10:42:50 +0000     1576424570      1576413702   \n",
      "10913  Sat, 12 Oct 2019 20:56:01 +0000     1570928161      1570922006   \n",
      "10914        2019-07-06 17:51:38+00:00     1562449898      1567536625   \n",
      "10915        2019-09-25 16:58:01+00:00     1569445081      1570222223   \n",
      "10916        2019-09-20 13:56:47+00:00     1569002207      1570222711   \n",
      "\n",
      "              category_level_1         category_level_2  encoded_label  \\\n",
      "0       crime, law and justice                    crime              0   \n",
      "1       crime, law and justice                    crime              0   \n",
      "2       crime, law and justice                    crime              0   \n",
      "3       crime, law and justice                    crime              0   \n",
      "4       crime, law and justice                    crime              0   \n",
      "...                        ...                      ...            ...   \n",
      "10912  conflict, war and peace  post-war reconstruction             15   \n",
      "10913  conflict, war and peace  post-war reconstruction             15   \n",
      "10914  conflict, war and peace  post-war reconstruction             15   \n",
      "10915  conflict, war and peace  post-war reconstruction             15   \n",
      "10916  conflict, war and peace  post-war reconstruction             15   \n",
      "\n",
      "                                               tokenized  \n",
      "0      ([tensor(101), tensor(1996), tensor(3448), ten...  \n",
      "1      ([tensor(101), tensor(4614), tensor(2024), ten...  \n",
      "2      ([tensor(101), tensor(1037), tensor(2410), ten...  \n",
      "3      ([tensor(101), tensor(1996), tensor(2388), ten...  \n",
      "4      ([tensor(101), tensor(1000), tensor(2028), ten...  \n",
      "...                                                  ...  \n",
      "10912  ([tensor(101), tensor(2023), tensor(2695), ten...  \n",
      "10913  ([tensor(101), tensor(2023), tensor(2695), ten...  \n",
      "10914  ([tensor(101), tensor(2023), tensor(1031), ten...  \n",
      "10915  ([tensor(101), tensor(2023), tensor(1031), ten...  \n",
      "10916  ([tensor(101), tensor(2023), tensor(1031), ten...  \n",
      "\n",
      "[10916 rows x 15 columns]\n",
      "tensor([[  101,  1996,  3448,  ...,     0,     0,     0],\n",
      "        [  101,  4614,  2024,  ..., 16337,  4645,   102],\n",
      "        [  101,  1037,  2410,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,  2023,  1031,  ...,  2048,  2086,   102],\n",
      "        [  101,  2023,  1031,  ...,  4736,  1012,   102],\n",
      "        [  101,  2023,  1031,  ...,  2490,  3426,   102]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]])\n",
      "tensor([ 0,  0,  0,  ..., 15, 15, 15])\n"
     ]
    }
   ],
   "source": [
    "# tokenizer cell \n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "max_length = 256\n",
    "\n",
    "def tokenize_text(text):\n",
    "    if not isinstance(text, str) or text.strip() == '':\n",
    "        raise ValueError(\"Input text must be a non-empty string.\")\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt' \n",
    "    )\n",
    "    return encoding['input_ids'][0], encoding['attention_mask'][0]\n",
    "\n",
    "df['tokenized'] = df['content'].apply(tokenize_text)\n",
    "print(df)\n",
    "\n",
    "input_ids = torch.stack([item[0] for item in df['tokenized']])\n",
    "attention_masks = torch.stack([item[1] for item in df['tokenized']])\n",
    "\n",
    "labels = torch.tensor(df['encoded_label'].values)\n",
    "\n",
    "\n",
    "print(input_ids)\n",
    "print(attention_masks)\n",
    "print(labels)\n",
    "\n",
    "\n",
    "train_inputs, val_inputs, train_labels, val_labels, train_masks, val_masks = train_test_split(\n",
    "    input_ids, labels, attention_masks, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a22eec47-c0a2-48ab-bb3b-2a4513602430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_inputs.numpy(),\n",
    "    \"attention_mask\": train_masks.numpy(),\n",
    "    \"labels\": train_labels.numpy()\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_inputs.numpy(),\n",
    "    \"attention_mask\": val_masks.numpy(),\n",
    "    \"labels\": val_labels.numpy()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c085c0-60b3-4336-b762-c8393132e219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is PyTorch available: True\n",
      "Is TensorFlow available: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model framework: pt\n"
     ]
    }
   ],
   "source": [
    "# load in the model \n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import transformers\n",
    "print(\"Is PyTorch available:\", transformers.is_torch_available())\n",
    "print(\"Is TensorFlow available:\", transformers.is_tf_available())\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(categories),\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "print(\"Model framework:\", model.framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a046c83-9445-4aa2-8a5d-5524b760da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics stuff \n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    logits, labels = pred\n",
    "    preds = logits.argmax(axis=-1) \n",
    "    \n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3214bd0-21eb-4018-9dad-0f1b679a28d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ht/fn30gwr12cq2x05xdbq8v2w80000gn/T/ipykernel_44831/4229264597.py:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model framework: pt\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "print(\"Model framework:\", model.framework)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results2\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\"\n",
    ")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0e2a38-7f5c-4c49-8d16-63b628d7a6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1272' max='2730' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1272/2730 30:39 < 35:11, 0.69 it/s, Epoch 2.33/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.264800</td>\n",
       "      <td>0.840766</td>\n",
       "      <td>0.759615</td>\n",
       "      <td>0.758857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.864545</td>\n",
       "      <td>0.761447</td>\n",
       "      <td>0.761267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train model cell \n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eb8132-deba-4989-b41a-00d0fdf636fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91caa657-f80a-43c7-999e-3afc46576628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./fine_tuned_bert2\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bert2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169b50a-03cb-440b-94d0-232826946d87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
